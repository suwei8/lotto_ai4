from __future__ import annotations

import collections

import pandas as pd
import streamlit as st

from db.connection import query_db
from utils.cache import cached_query
from utils.charts import render_digit_frequency_chart
from utils.data_access import (
    fetch_playtypes_for_issue,
)
from utils.numbers import match_prediction_hit, normalize_code, parse_tokens
from utils.sql import make_in_clause
from utils.ui import issue_picker, playtype_picker, render_open_info

st.set_page_config(page_title="Lotto AI", layout="wide")

st.header("FilterTool_MissV2 - ç»„åˆç¼ºå¤±ç­›é€‰")

selected_issue = issue_picker(
    "filter_miss_issue",
    mode="single",
    label="å½“å‰æœŸå·",
    max_issues=300,
)
if not selected_issue:
    st.stop()

render_open_info(selected_issue, key="filter_miss_open", show_metrics=False)

playtype_df = fetch_playtypes_for_issue(selected_issue)
if playtype_df.empty:
    st.info("å½“å‰æœŸæš‚æ— ä¸“å®¶æ¨èã€‚")
    st.stop()

playtype_map: dict[int, str] = {
    int(row.playtype_id): row.playtype_name for row in playtype_df.itertuples()
}
playtype_ids = list(playtype_map.keys())

raw_playtypes = playtype_picker(
    "filter_miss_current_playtypes",
    mode="multi",
    label="ğŸ® å½“å‰æœŸç»Ÿè®¡ç©æ³•ï¼ˆå¯å¤šé€‰ï¼‰",
    include=[str(pid) for pid in playtype_ids],
    default=[str(playtype_ids[0])] if playtype_ids else [],
)
selected_playtypes = [int(pid) for pid in raw_playtypes]

issue_rows = cached_query(
    query_db,
    """
    SELECT DISTINCT issue_name
    FROM expert_predictions
    ORDER BY issue_name DESC
    LIMIT 500
    """,
    params=None,
    ttl=300,
)
issue_list_all = [row["issue_name"] for row in issue_rows]
if selected_issue not in issue_list_all:
    issue_list_all.insert(0, selected_issue)

if not issue_list_all:
    st.warning("æš‚æ— ä¸“å®¶å†å²æœŸå·æ•°æ®ã€‚")
    st.stop()

with st.expander("ğŸ” ç­›é™¤è¿ç»­æœªå‘½ä¸­AIæ™ºä½“è®¾ç½®", expanded=True):
    try:
        current_index = issue_list_all.index(selected_issue)
    except ValueError:
        current_index = 0

    if current_index + 1 < len(issue_list_all):
        default_end_issue = issue_list_all[current_index + 1]
    else:
        default_end_issue = issue_list_all[current_index]

    ref_issue = st.selectbox(
        "ğŸ—•ï¸ å›æº¯ç»Ÿè®¡æˆªè‡³æœŸå·",
        options=issue_list_all,
        index=issue_list_all.index(default_end_issue) if default_end_issue in issue_list_all else 0,
    )

    ref_index = issue_list_all.index(ref_issue)
    max_lookback_n = len(issue_list_all) - ref_index
    max_lookback_n = max(max_lookback_n, 1)

    lookback_n = st.slider("ğŸ“… å›æº¯æœŸæ•°ï¼ˆLookback NæœŸï¼‰", 1, max_lookback_n, 1)

    enable_miss_threshold_config = st.checkbox("âœï¸ æ‰‹åŠ¨è®¾ç½®æœªå‘½ä¸­æ¬¡æ•°ç­›é€‰åŒºé—´", value=False)

    if enable_miss_threshold_config:
        if "miss_threshold_low" not in st.session_state:
            st.session_state["miss_threshold_low"] = 0
        if "miss_threshold_high" not in st.session_state:
            st.session_state["miss_threshold_high"] = 0

        low_default = min(int(st.session_state["miss_threshold_low"]), lookback_n)
        high_default = min(int(st.session_state["miss_threshold_high"]), lookback_n)
        if high_default < low_default:
            high_default = low_default

        miss_threshold_low = st.slider(
            "ğŸ“‰ æœ€å°‘æœªå‘½ä¸­æ¬¡æ•°ï¼ˆä½åŒºé—´ï¼‰",
            min_value=0,
            max_value=lookback_n,
            value=low_default,
            key="miss_threshold_low",
        )
        miss_threshold_high = st.slider(
            "ğŸ“ˆ æœ€å¤§æœªå‘½ä¸­æ¬¡æ•°ï¼ˆé«˜åŒºé—´ï¼‰",
            min_value=0,
            max_value=lookback_n,
            value=high_default,
            key="miss_threshold_high",
        )
    else:
        miss_threshold_low = 0
        miss_threshold_high = 0

    remove_duplicates = st.checkbox("ğŸ§¹ æ˜¯å¦å»é‡åŒä¸“å®¶åŒç©æ³•è®°å½•", value=True)

    raw_ref_playtypes = playtype_picker(
        "filter_miss_ref_playtypes",
        mode="multi",
        label="ğŸ¯ å›æº¯ç©æ³•ï¼ˆå¯å¤šé€‰ï¼‰",
        include=[str(pid) for pid in playtype_ids],
        default=(
            [str(pid) for pid in selected_playtypes]
            if selected_playtypes
            else [str(playtype_ids[0])] if playtype_ids else []
        ),
    )
    ref_playtypes = [int(pid) for pid in raw_ref_playtypes]

    filter_mode = st.selectbox(
        "ğŸ¯ ç­›é€‰æ¨¡å¼",
        options=[
            f"ä¿ç•™æœªå‘½ä¸­æ¬¡æ•° â‰¤ {miss_threshold_high} çš„ä¸“å®¶ï¼ˆé«˜å‘½ä¸­ï¼‰",
            f"ä¿ç•™ {miss_threshold_low} â‰¤ æœªå‘½ä¸­æ¬¡æ•° â‰¤ {miss_threshold_high} çš„ä¸“å®¶ï¼ˆä¸­å‘½ä¸­ï¼‰",
            "ä¿ç•™è¿ç»­å¿…ä¸­ä¸“å®¶ï¼ˆæœªå‘½ä¸­=0ï¼‰",
            f"ä¿ç•™è¿ç»­æœªå‘½ä¸­ä¸“å®¶ï¼ˆæœªå‘½ä¸­={lookback_n}ï¼‰",
        ],
    )

    enable_filter = st.checkbox("ğŸ§Š å¯ç”¨ç­›é€‰", value=True)


if st.button("ğŸš€ æŸ¥è¯¢æ¨èæ•°å­—é¢‘æ¬¡"):
    if not selected_playtypes:
        st.warning("âš ï¸ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªç©æ³•ã€‚")
        st.stop()

    if enable_filter and not ref_playtypes:
        st.warning("âš ï¸ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªå›æº¯ç©æ³•ç”¨äºç­›é€‰ã€‚")
        st.stop()

    with st.spinner("æŸ¥è¯¢ä¸­..."):
        try:
            current_clause, current_params = make_in_clause(
                "playtype_id", [int(pid) for pid in selected_playtypes], "cur"
            )
            current_params.update({"issue": selected_issue})
            sql_current = f"""
                SELECT user_id, playtype_id, numbers
                FROM expert_predictions
                WHERE issue_name = :issue
                  AND {current_clause}
            """
            current_rows = cached_query(query_db, sql_current, params=current_params, ttl=120)
        except Exception as exc:  # pragma: no cover - defensive UI guard
            st.error(f"åŠ è½½å½“å‰æœŸæ¨èå¤±è´¥ï¼š{exc}")
            st.stop()

        current_df = pd.DataFrame(current_rows)
        if current_df.empty:
            st.info("å½“å‰æœŸæš‚æ— ç¬¦åˆæ¡ä»¶çš„ä¸“å®¶æ¨èã€‚")
            st.stop()

        current_df["playtype_id"] = current_df["playtype_id"].astype(int)

        if remove_duplicates:
            current_df.drop_duplicates(subset=["user_id", "playtype_id", "numbers"], inplace=True)

        try:
            issue_rows = cached_query(
                query_db,
                """
                SELECT DISTINCT issue_name
                FROM expert_predictions
                WHERE issue_name <= :ref_issue
                ORDER BY issue_name DESC
                LIMIT :limit
                """,
                params={"ref_issue": ref_issue, "limit": lookback_n},
                ttl=120,
            )
        except Exception as exc:  # pragma: no cover - defensive UI guard
            st.error(f"åŠ è½½å›æº¯æœŸå·å¤±è´¥ï¼š{exc}")
            st.stop()

        issue_list = sorted({row["issue_name"] for row in issue_rows})
        if not issue_list:
            st.info("æ‰€é€‰å›æº¯èŒƒå›´å†…æ— ä¸“å®¶æ¨èè®°å½•ã€‚")
            st.stop()

        result_clause, result_params = make_in_clause("issue_name", issue_list, "res")
        sql_result = f"""
            SELECT issue_name, open_code
            FROM lottery_results
            WHERE {result_clause}
        """
        result_rows = cached_query(query_db, sql_result, params=result_params, ttl=120)
        result_map = {
            row["issue_name"]: normalize_code(row.get("open_code")) for row in result_rows
        }

        history_df = pd.DataFrame()
        if ref_playtypes:
            history_clause, history_params = make_in_clause("issue_name", issue_list, "hist")
            playtype_clause, playtype_params = make_in_clause(
                "playtype_id", [int(pid) for pid in ref_playtypes], "pt"
            )
            history_params.update(playtype_params)
            sql_history = f"""
                SELECT issue_name, playtype_id, user_id, numbers
                FROM expert_predictions
                WHERE {history_clause}
                  AND {playtype_clause}
            """
            try:
                history_rows = cached_query(query_db, sql_history, params=history_params, ttl=120)
            except Exception as exc:  # pragma: no cover - defensive UI guard
                st.error(f"åŠ è½½å›æº¯æ¨èå¤±è´¥ï¼š{exc}")
                st.stop()
            history_df = pd.DataFrame(history_rows)
            history_df["playtype_id"] = history_df["playtype_id"].astype(int)

        kept_users: set[str]
        if enable_filter and not history_df.empty:
            kept: list[str] = []
            issue_sequence = sorted(issue_list)
            result_lookup = result_map

            for user_id, group in history_df.groupby("user_id"):
                group = group.drop_duplicates(subset=["issue_name", "playtype_id", "numbers"])
                group = group[group["issue_name"].isin(issue_sequence)]
                if len(group) < lookback_n:
                    continue

                group = group.sort_values("issue_name")
                group_dict = group.set_index("issue_name")
                hits: list[bool] = []

                for issue in issue_sequence:
                    if issue not in group_dict.index:
                        continue
                    row = group_dict.loc[[issue]].iloc[0]
                    open_code = result_lookup.get(issue)
                    if not open_code:
                        continue
                    playtype_name = playtype_map.get(
                        int(row["playtype_id"]), str(row["playtype_id"])
                    )
                    hit = match_prediction_hit(playtype_name, row["numbers"], open_code)
                    hits.append(hit)

                miss_count = hits.count(False)
                if f"æœªå‘½ä¸­æ¬¡æ•° â‰¤ {miss_threshold_high}" in filter_mode:
                    if miss_count <= miss_threshold_high:
                        kept.append(user_id)
                elif f"{miss_threshold_low} â‰¤ æœªå‘½ä¸­æ¬¡æ•° â‰¤ {miss_threshold_high}" in filter_mode:
                    if miss_threshold_low <= miss_count <= miss_threshold_high:
                        kept.append(user_id)
                elif "è¿ç»­å¿…ä¸­" in filter_mode:
                    if miss_count == 0:
                        kept.append(user_id)
                elif "è¿ç»­æœªå‘½ä¸­" in filter_mode:
                    if hits.count(True) == 0:
                        kept.append(user_id)

            kept_users = set(kept)
        elif enable_filter and history_df.empty:
            kept_users = set()
        else:
            kept_users = set(current_df["user_id"].unique())

        if enable_filter:
            current_df = current_df[current_df["user_id"].isin(kept_users)]

        if current_df.empty:
            st.info("æ— ç¬¦åˆç­›é€‰æ¡ä»¶çš„ä¸“å®¶æ¨èã€‚")
            st.stop()

        if remove_duplicates and not current_df.empty:
            current_df.drop_duplicates(subset=["user_id", "playtype_id", "numbers"], inplace=True)

        freq_counter = collections.Counter()
        for numbers in current_df["numbers"]:
            for token in parse_tokens(numbers):
                key = normalize_code(token) or token.strip()
                if key:
                    freq_counter[key] += 1

        if not freq_counter:
            st.warning("âš ï¸ æ— æ¨èæ•°æ®å¯ç”¨äºç»Ÿè®¡ã€‚")
            st.stop()

        freq_df = (
            pd.DataFrame(
                {"æ•°å­—": list(freq_counter.keys()), "æ¨èæ¬¡æ•°": list(freq_counter.values())}
            )
            .sort_values(by="æ¨èæ¬¡æ•°", ascending=False)
            .reset_index(drop=True)
        )

        st.subheader("æ¨èæ•°å­—é¢‘æ¬¡")
        st.dataframe(freq_df, use_container_width=True)

        chart = render_digit_frequency_chart(
            freq_df,
            digit_column="æ•°å­—",
            count_column="æ¨èæ¬¡æ•°",
        )
        if chart is not None:
            st.altair_chart(chart, use_container_width=True)

        included_user_ids = current_df["user_id"].unique().tolist()
        st.markdown(f"### âœ… å½“å‰æœŸå®é™…å‚ä¸ç»Ÿè®¡çš„AIæ™ºä½“ï¼ˆ{len(included_user_ids)}ä¸ªï¼‰")

        if included_user_ids:
            user_clause, user_params = make_in_clause("user_id", included_user_ids, "user")
            sql_users = f"""
                SELECT user_id, nick_name
                FROM expert_info
                WHERE {user_clause}
            """
            user_rows = cached_query(query_db, sql_users, params=user_params, ttl=300)
            user_info_df = pd.DataFrame(user_rows)

            current_df["playtype_name"] = current_df["playtype_id"].apply(
                lambda pid: playtype_map.get(pid, str(pid))
            )
            recommend_df = current_df.copy()
            recommend_df["æ¨èé¡¹"] = recommend_df.apply(
                lambda row: f"{row['playtype_name']}: {row['numbers']}", axis=1
            )
            recommend_summary = (
                recommend_df.groupby("user_id")["æ¨èé¡¹"]
                .apply(lambda values: " / ".join(sorted(set(values))))
                .reset_index()
            )

            display_df = user_info_df.merge(recommend_summary, on="user_id", how="left").rename(
                columns={
                    "user_id": "ç”¨æˆ·ID",
                    "nick_name": "ä¸“å®¶æ˜µç§°",
                    "æ¨èé¡¹": "æ¨èæ•°å­—",
                }
            )
            display_df.sort_values("ç”¨æˆ·ID", inplace=True)

            st.subheader("å‚ä¸ç»Ÿè®¡çš„ä¸“å®¶")
            st.dataframe(display_df, use_container_width=True)
        else:
            st.info("æš‚æ— AIæ™ºä½“å‚ä¸å½“å‰ç»Ÿè®¡ã€‚")
