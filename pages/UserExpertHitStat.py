from __future__ import annotations

import re
from collections import Counter
from typing import Dict, Iterable, List, Sequence, Tuple

import altair as alt
import pandas as pd
import streamlit as st

from db.connection import query_db
from utils.cache import cached_query
from utils.data_access import (
    fetch_lottery_info,
    fetch_playtypes,
)
from utils.numbers import match_prediction_hit, normalize_code, parse_tokens
from utils.charts import render_digit_frequency_chart
from utils.sql import make_in_clause


st.set_page_config(page_title="AI å‘½ä¸­ç»Ÿè®¡åˆ†æ", layout="wide")
st.header("UserExpertHitStat - AI å‘½ä¸­è¡¨ç°åˆ†æ")
st.caption("å›ºå®šå½©ç§ï¼šç¦å½©3D")

# --------- å¸¸é‡ä¸è¾…åŠ©é…ç½® ---------
POSITIONAL_PLAYTYPES: Dict[str, int] = {
    "ç™¾ä½å®š3": 0,
    "åä½å®š3": 1,
    "ä¸ªä½å®š3": 2,
    "ç™¾ä½å®š1": 0,
    "åä½å®š1": 1,
    "ä¸ªä½å®š1": 2,
    "å®šä½3*3*3-ç™¾ä½": 0,
    "å®šä½3*3*3-åä½": 1,
    "å®šä½3*3*3-ä¸ªä½": 2,
    "å®šä½4*4*4-ç™¾ä½": 0,
    "å®šä½4*4*4-åä½": 1,
    "å®šä½4*4*4-ä¸ªä½": 2,
    "å®šä½5*5*5-ç™¾ä½": 0,
    "å®šä½5*5*5-åä½": 1,
    "å®šä½5*5*5-ä¸ªä½": 2,
    "ä¸‡ä½æ€3": 0,
    "åƒä½æ€3": 1,
    "ç™¾ä½æ€3": 2,
    "åä½æ€3": 3,
    "ä¸ªä½æ€3": 4,
    "ä¸‡ä½æ€1": 0,
    "åƒä½æ€1": 1,
    "ç™¾ä½æ€1": 2,
    "åä½æ€1": 3,
    "ä¸ªä½æ€1": 4,
    "ä¸‡ä½å®š5": 0,
    "åƒä½å®š5": 1,
    "ç™¾ä½å®š5": 2,
    "åä½å®š5": 3,
    "ä¸ªä½å®š5": 4,
    "ä¸‡ä½å®š3": 0,
    "åƒä½å®š3": 1,
    "ä¸‡ä½å®š1": 0,
    "åƒä½å®š1": 1,
}

PLAYTYPE_DICT = fetch_playtypes()
PLAYTYPE_NAME_TO_ID: Dict[str, int] = (
    {row.playtype_name: int(row.playtype_id) for row in PLAYTYPE_DICT.itertuples()}
    if not PLAYTYPE_DICT.empty
    else {}
)
PLAYTYPE_ID_TO_NAME: Dict[int, str] = (
    {int(row.playtype_id): row.playtype_name for row in PLAYTYPE_DICT.itertuples()}
    if not PLAYTYPE_DICT.empty
    else {}
)


# --------- æ•°æ®æŸ¥è¯¢è¾…åŠ©å‡½æ•° ---------

def fetch_stat_issues() -> List[str]:
    rows = cached_query(
        query_db,
        "SELECT DISTINCT issue_name FROM expert_hit_stat ORDER BY issue_name DESC",
        params=None,
        ttl=120,
    )
    return [str(row["issue_name"]) for row in rows]


def fetch_playtypes_for_issue(issue: str) -> List[Tuple[int, str]]:
    rows = cached_query(
        query_db,
        """
        SELECT DISTINCT s.playtype_id AS pid, d.playtype_name AS pname
        FROM expert_hit_stat s
        JOIN playtype_dict d ON d.playtype_id = s.playtype_id
        WHERE s.issue_name = :issue
        ORDER BY s.playtype_id
        """,
        params={"issue": issue},
        ttl=120,
    )
    return [
        (int(row["pid"]), row.get("pname") or PLAYTYPE_ID_TO_NAME.get(int(row["pid"]), str(row["pid"])))
        for row in rows
    ]


def fetch_hit_summary(issues: Sequence[str], playtype_id: int) -> pd.DataFrame:
    if not issues:
        return pd.DataFrame(columns=["user_id", "total_count", "hit_count", "hit_number_count"])
    clause, params = make_in_clause("issue_name", issues, "issue")
    params["playtype"] = int(playtype_id)
    sql = f"""
        SELECT user_id,
               SUM(total_count) AS total_count,
               SUM(hit_count) AS hit_count,
               SUM(hit_number_count) AS hit_number_count
        FROM expert_hit_stat
        WHERE {clause} AND playtype_id = :playtype
        GROUP BY user_id
    """
    rows = cached_query(query_db, sql, params=params, ttl=120)
    return pd.DataFrame(rows)


def fetch_nick_map(user_ids: Iterable[int]) -> Dict[int, str]:
    ids = list(user_ids)
    if not ids:
        return {}
    clause, params = make_in_clause("user_id", ids, "uid")
    sql = f"SELECT user_id, nick_name FROM expert_info WHERE {clause}"
    rows = cached_query(query_db, sql, params=params, ttl=300)
    return {int(row["user_id"]): row.get("nick_name") or "æœªçŸ¥" for row in rows}


def fetch_query_issues() -> List[str]:
    sql = """
        SELECT issue_name
        FROM (
            SELECT DISTINCT issue_name FROM expert_hit_stat
            UNION
            SELECT DISTINCT issue_name FROM expert_predictions
        ) AS merged
        ORDER BY issue_name DESC
    """
    rows = cached_query(query_db, sql, params=None, ttl=120)
    return [str(row["issue_name"]) for row in rows]


def fetch_last_hit_status(issue: str, playtype_id: int) -> Tuple[set[int], set[int]]:
    rows = cached_query(
        query_db,
        """
        SELECT user_id, hit_count
        FROM expert_hit_stat
        WHERE issue_name = :issue AND playtype_id = :playtype
        """,
        params={"issue": issue, "playtype": int(playtype_id)},
        ttl=120,
    )
    hit_users = {int(row["user_id"]) for row in rows if row.get("hit_count", 0)}
    miss_users = {int(row["user_id"]) for row in rows if not row.get("hit_count", 0)}
    return hit_users, miss_users


def fetch_predictions_for_users(issue: str, playtype_id: int, user_ids: Sequence[int]) -> pd.DataFrame:
    ids = list(user_ids)
    if not ids:
        return pd.DataFrame(columns=["user_id", "numbers"])
    clause, params = make_in_clause("user_id", ids, "uid")
    params.update({"issue": issue, "playtype": int(playtype_id)})
    sql = f"""
        SELECT user_id, numbers
        FROM expert_predictions
        WHERE issue_name = :issue AND playtype_id = :playtype AND {clause}
    """
    rows = cached_query(query_db, sql, params=params, ttl=120)
    return pd.DataFrame(rows)


# --------- é¡µé¢ä¸»æµç¨‹ ---------

issues = fetch_stat_issues()
if not issues:
    st.warning("æ— æ³•è·å–æœŸå·åˆ—è¡¨ã€‚")
    st.stop()

selected_issues = st.multiselect(
    "ğŸ“… é€‰æ‹©æœŸå·ï¼ˆé»˜è®¤å…¨é€‰ï¼‰",
    options=issues,
    default=issues,
)
if not selected_issues:
    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæœŸå·ã€‚")
    st.stop()

first_issue = selected_issues[0]
playtype_pairs = fetch_playtypes_for_issue(first_issue)
if not playtype_pairs:
    st.info("æ‰€é€‰æœŸå·æš‚æ— ç©æ³•æ•°æ®ã€‚")
    st.stop()

playtype_ids = [pid for pid, _ in playtype_pairs]
playtype_name_map = {pid: name for pid, name in playtype_pairs}

selected_playtype_id = st.selectbox(
    "ğŸ® é€‰æ‹©ç©æ³•",
    options=playtype_ids,
    format_func=lambda pid: playtype_name_map.get(pid, PLAYTYPE_ID_TO_NAME.get(pid, str(pid))),
)
selected_playtype_name = playtype_name_map.get(
    selected_playtype_id, PLAYTYPE_ID_TO_NAME.get(selected_playtype_id, str(selected_playtype_id))
)

if st.button("ğŸ“Š åˆ†æ AI å‘½ä¸­è¡¨ç°"):
    summary_df = fetch_hit_summary(selected_issues, selected_playtype_id)
    if summary_df.empty:
        st.info("æ‰€é€‰æ¡ä»¶ä¸‹æ— å‘½ä¸­ç»Ÿè®¡æ•°æ®ã€‚")
    else:
        summary_df["user_id"] = summary_df["user_id"].astype(int)
        nick_map = fetch_nick_map(summary_df["user_id"].tolist())
        summary_df["é¢„æµ‹æœŸæ•°"] = summary_df["total_count"].fillna(0).astype(int)
        summary_df["å‘½ä¸­æœŸæ•°"] = summary_df["hit_count"].fillna(0).astype(int)
        summary_df["å‘½ä¸­æ•°å­—æ•°é‡"] = summary_df["hit_number_count"].fillna(0).astype(int)
        summary_df["å‘½ä¸­ç‡"] = summary_df.apply(
            lambda row: round(row["å‘½ä¸­æ•°å­—æ•°é‡"] / row["é¢„æµ‹æœŸæ•°"], 4)
            if row["é¢„æµ‹æœŸæ•°"]
            else 0,
            axis=1,
        )
        summary_df["AIæ˜µç§°"] = summary_df["user_id"].map(nick_map).fillna("æœªçŸ¥")
        result_df = summary_df[
            ["user_id", "AIæ˜µç§°", "å‘½ä¸­æœŸæ•°", "é¢„æµ‹æœŸæ•°", "å‘½ä¸­æ•°å­—æ•°é‡", "å‘½ä¸­ç‡"]
        ].sort_values(by="å‘½ä¸­ç‡", ascending=False)
        st.session_state["uehs_summary"] = {
            "result": result_df.reset_index(drop=True),
            "issues": list(selected_issues),
            "playtype_id": int(selected_playtype_id),
            "playtype_name": selected_playtype_name,
            "playtype_options": playtype_pairs,
        }

if "uehs_summary" not in st.session_state:
    st.stop()

state = st.session_state["uehs_summary"]
result_df: pd.DataFrame = state["result"]
history_issues: List[str] = state["issues"]
selected_playtype_id: int = state["playtype_id"]
selected_playtype_name: str = state.get(
    "playtype_name", PLAYTYPE_ID_TO_NAME.get(selected_playtype_id, str(selected_playtype_id))
)
playtype_pairs = state.get("playtype_options", [])
if not playtype_pairs:
    playtype_pairs = fetch_playtypes_for_issue(history_issues[0])

st.markdown(f"### ğŸ“‹ AI å‘½ä¸­è¡¨ç°ç»Ÿè®¡è¡¨ï¼ˆå…± {len(result_df)} ä½ï¼‰")
if result_df.empty:
    st.info("æ— ç»Ÿè®¡æ•°æ®ã€‚")
    st.stop()

# åˆ†å¸ƒç»Ÿè®¡ - å‘½ä¸­æœŸæ•°
hit_counts = result_df["å‘½ä¸­æœŸæ•°"].value_counts().sort_index()
total_users = len(result_df)
hit_lines = [
    f"<b>å‘½ä¸­æœŸæ•° {val}</b>ï¼š{count} äººï¼ˆå æ¯” {round(count / total_users * 100, 2)}%ï¼‰"
    for val, count in hit_counts.items()
]
columns = [[], [], [], []]
for idx, line in enumerate(hit_lines):
    columns[idx % 4].append(line)
block = "".join(
    f"<div style='flex:1'>{'<br>'.join(col)}</div>" for col in columns if col
)
st.markdown("**å‘½ä¸­æœŸæ•°åˆ†å¸ƒç»Ÿè®¡ï¼š**", unsafe_allow_html=True)
st.markdown(f"<div style='display:flex;gap:24px'>{block}</div>", unsafe_allow_html=True)

# åˆ†å¸ƒç»Ÿè®¡ - å‘½ä¸­æ•°å­—æ•°é‡
hit_num_counts = result_df["å‘½ä¸­æ•°å­—æ•°é‡"].value_counts().sort_index()
num_lines = [
    f"<b>å‘½ä¸­æ•°å­—æ•°é‡ {val}</b>ï¼š{count} äººï¼ˆå æ¯” {round(count / total_users * 100, 2)}%ï¼‰"
    for val, count in hit_num_counts.items()
]
columns2 = [[], [], [], []]
for idx, line in enumerate(num_lines):
    columns2[idx % 4].append(line)
block2 = "".join(
    f"<div style='flex:1'>{'<br>'.join(col)}</div>" for col in columns2 if col
)
st.markdown("**å‘½ä¸­æ•°å­—æ•°é‡åˆ†å¸ƒç»Ÿè®¡ï¼š**", unsafe_allow_html=True)
st.markdown(f"<div style='display:flex;gap:24px'>{block2}</div>", unsafe_allow_html=True)

st.dataframe(
    result_df[["user_id", "AIæ˜µç§°", "å‘½ä¸­æœŸæ•°", "é¢„æµ‹æœŸæ•°", "å‘½ä¸­æ•°å­—æ•°é‡", "å‘½ä¸­ç‡"]],
    use_container_width=True,
    hide_index=True,
)

# --------- æ¨èè®°å½•åæŸ¥ä¸å¯è§†åŒ– ---------
st.markdown("---")
st.markdown("### ğŸ” æŒ‰å‘½ä¸­æ¡ä»¶ç­›é€‰ä¸“å®¶å¹¶åæŸ¥æ¨èè®°å½•")

hit_options = sorted(result_df["å‘½ä¸­æœŸæ•°"].unique())
num_hit_options = sorted(result_df["å‘½ä¸­æ•°å­—æ•°é‡"].unique())
selected_hit_values = st.multiselect(
    "ğŸ¯ å‘½ä¸­æœŸæ•°ç­›é€‰",
    options=hit_options,
    default=hit_options,
)
selected_num_hit_values = st.multiselect(
    "ğŸ¯ å‘½ä¸­æ•°å­—æ•°é‡ç­›é€‰",
    options=num_hit_options,
    default=num_hit_options,
)
hit_status_filter = st.radio(
    "ğŸ¯ ä¸ŠæœŸå‘½ä¸­çŠ¶æ€",
    options=["ä¸è¿‡æ»¤", "ä¸ŠæœŸå‘½ä¸­", "ä¸ŠæœŸæœªå‘½ä¸­"],
    horizontal=True,
)

query_issue_options = fetch_query_issues()
if not query_issue_options:
    query_issue_options = history_issues
query_issue = st.selectbox("ğŸ“… æŸ¥è¯¢æœŸå·", options=query_issue_options)

query_playtype_ids = [pid for pid, _ in playtype_pairs]
query_playtype_name_map = {pid: name for pid, name in playtype_pairs}
default_index = query_playtype_ids.index(selected_playtype_id) if selected_playtype_id in query_playtype_ids else 0
query_playtype_id = st.selectbox(
    "ğŸ® æŸ¥è¯¢ç©æ³•",
    options=query_playtype_ids,
    index=default_index,
    format_func=lambda pid: query_playtype_name_map.get(pid, PLAYTYPE_ID_TO_NAME.get(pid, str(pid))),
)
query_playtype_name = query_playtype_name_map.get(
    query_playtype_id, PLAYTYPE_ID_TO_NAME.get(query_playtype_id, str(query_playtype_id))
)

if st.button("ğŸ“¥ æŸ¥è¯¢æ¨èè®°å½•"):
    filtered = result_df[
        result_df["å‘½ä¸­æœŸæ•°"].isin(selected_hit_values)
        & result_df["å‘½ä¸­æ•°å­—æ•°é‡"].isin(selected_num_hit_values)
    ]

    if filtered.empty:
        st.warning("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰ä¸“å®¶ã€‚")
        st.session_state.pop("uehs_records", None)
    else:
        # ä¸ŠæœŸå‘½ä¸­ç­›é€‰
        if hit_status_filter != "ä¸è¿‡æ»¤":
            try:
                issue_idx = query_issue_options.index(query_issue)
            except ValueError:
                issue_idx = -1
            last_issue = query_issue_options[issue_idx + 1] if issue_idx >= 0 and issue_idx + 1 < len(query_issue_options) else None
            hit_users_last: set[int] = set()
            miss_users_last: set[int] = set()
            if last_issue:
                hit_users_last, miss_users_last = fetch_last_hit_status(last_issue, query_playtype_id)
            if hit_status_filter == "ä¸ŠæœŸå‘½ä¸­":
                filtered = filtered[filtered["user_id"].isin(hit_users_last)]
            else:
                filtered = filtered[filtered["user_id"].isin(miss_users_last)]
        if filtered.empty:
            st.warning("ç­›é€‰æ¡ä»¶ä¸‹æ— ä¸“å®¶ç¬¦åˆã€‚")
            st.session_state.pop("uehs_records", None)
        else:
            rec_df = fetch_predictions_for_users(
                query_issue, query_playtype_id, filtered["user_id"].tolist()
            )
            st.session_state["uehs_records"] = {
                "records": rec_df,
                "issue": query_issue,
                "playtype_id": int(query_playtype_id),
                "playtype_name": query_playtype_name,
                "nick_map": dict(zip(result_df["user_id"], result_df["AIæ˜µç§°"])),
            }

if "uehs_records" in st.session_state:
    record_state = st.session_state["uehs_records"]
    rec_df: pd.DataFrame = record_state.get("records", pd.DataFrame())
    issue_for_display: str = record_state.get("issue", "")
    playtype_id_for_display: int = record_state.get("playtype_id", selected_playtype_id)
    playtype_name_for_display: str = record_state.get(
        "playtype_name",
        PLAYTYPE_ID_TO_NAME.get(playtype_id_for_display, str(playtype_id_for_display)),
    )
    nick_map: Dict[int, str] = record_state.get("nick_map", {})

    if rec_df.empty:
        st.info("ç­›é€‰æ¡ä»¶ä¸‹æœªæ‰¾åˆ°æ¨èè®°å½•ã€‚")
    else:
        rec_df["user_id"] = rec_df["user_id"].astype(int)
        open_info = fetch_lottery_info(issue_for_display) or {}
        open_code = open_info.get("open_code")
        blue_code = open_info.get("blue_code")
        has_open_code = bool(open_code)

        st.markdown(f"### ğŸ“‹ æ¨èè®°å½•ï¼ˆ{issue_for_display} æœŸï¼‰ - å…± {len(rec_df)} æ¡")
        if has_open_code:
            st.markdown("### ğŸ§§ å¼€å¥–ä¿¡æ¯", unsafe_allow_html=True)
            st.markdown(
                f"""
                <div style='font-size: 18px; line-height: 1.6;'>
                    ğŸ† <b>å¼€å¥–å·ç ï¼š</b> <span style='color: green; font-weight: bold;'>{open_code}</span>
                    <span style='margin-left: 32px;'>ğŸ”µ <b>è“çƒï¼š</b> <span style='color: blue; font-weight: bold;'>{blue_code or 'æ— '}</span></span>
                </div>
                """,
                unsafe_allow_html=True,
            )

        number_counter: Counter[str] = Counter()
        for numbers in rec_df["numbers"]:
            for token in parse_tokens(numbers):
                number_counter.update(list(token))

        if number_counter:
            freq_df = (
                pd.DataFrame(
                    [{"æ•°å­—": digit, "å‡ºç°æ¬¡æ•°": count} for digit, count in number_counter.items()]
                )
                .sort_values("å‡ºç°æ¬¡æ•°", ascending=False)
                .reset_index(drop=True)
            )
            normalized_open = normalize_code(open_code) if open_code else ""
            open_digits = list(normalized_open)
            positional_index = POSITIONAL_PLAYTYPES.get(playtype_name_for_display)

            def digit_hit(digit: str) -> bool:
                if not has_open_code:
                    return False
                if positional_index is not None:
                    digits_list = list(normalized_open)
                    if positional_index < len(digits_list):
                        return digit == digits_list[positional_index]
                    return False
                target_set = set(open_digits)
                if blue_code:
                    target_set.update(list(normalize_code(str(blue_code))))
                return digit in target_set

            freq_df["æ˜¯å¦å‘½ä¸­"] = freq_df["æ•°å­—"].apply(lambda d: "âœ…" if digit_hit(d) else "")
            hit_digit_count = int((freq_df["æ˜¯å¦å‘½ä¸­"] == "âœ…").sum())
            st.markdown(
                f"#### ğŸ¯ æ¨èæ•°å­—å‡ºç°é¢‘æ¬¡çƒ­åŠ›å›¾ï¼ˆå…± {len(freq_df)} ä¸ªæ•°å­—ï¼Œå‘½ä¸­ï¼š{hit_digit_count} ä¸ªï¼‰"
            )
            chart = render_digit_frequency_chart(
                freq_df.rename(columns={"å‡ºç°æ¬¡æ•°": "è¢«æ¨èæ¬¡æ•°"}),
                digit_column="æ•°å­—",
                count_column="è¢«æ¨èæ¬¡æ•°",
                hit_digits=open_digits if has_open_code else None,
                height=min(40 * len(freq_df), 800),
            )
            if chart is not None:
                st.altair_chart(chart, use_container_width=True)
        else:
            st.info("æš‚æ— æ¨èæ•°å­—ç»Ÿè®¡æ•°æ®ã€‚")

        detail_rows: List[Dict[str, object]] = []
        normalized_open_digits = set(list(normalize_code(open_code))) if open_code else set()
        if blue_code:
            normalized_open_digits.update(list(normalize_code(str(blue_code))))

        for row in rec_df.itertuples():
            uid = int(row.user_id)
            numbers = row.numbers
            digits = set("".join(parse_tokens(numbers)))
            hit_digits = normalized_open_digits & digits if has_open_code else set()
            if has_open_code:
                is_hit = match_prediction_hit(playtype_name_for_display, numbers, open_code or "")
            else:
                is_hit = None
            detail_rows.append(
                {
                    "user_id": uid,
                    "AIæ˜µç§°": nick_map.get(uid, "æœªçŸ¥"),
                    "æ¨èå·ç ": numbers,
                    "å‘½ä¸­æ•°é‡": len(hit_digits) if has_open_code else "-",
                    "æ˜¯å¦å‘½ä¸­": "âœ…" if is_hit else ("âŒ" if is_hit is False else "-"),
                }
            )

        detail_df = pd.DataFrame(detail_rows)
        if has_open_code and not detail_df.empty:
            detail_df = detail_df.sort_values(by="å‘½ä¸­æ•°é‡", ascending=False)
        st.markdown("### ğŸ“‹ æ¨èè¯¦æƒ…è¡¨æ ¼")
        st.dataframe(detail_df.reset_index(drop=True), use_container_width=True)

        st.markdown("### ğŸ§® å·ç ç»„åˆç»Ÿè®¡")
        combo_counter = Counter(rec_df["numbers"])
        combo_df = (
            pd.DataFrame(combo_counter.items(), columns=["å·ç ç»„åˆ", "å‡ºç°æ¬¡æ•°"])
            .sort_values("å‡ºç°æ¬¡æ•°", ascending=False)
            .reset_index(drop=True)
        )
        digits_options = [str(i) for i in range(10)]
        exclude_digits = st.multiselect("ğŸš« æ’é™¤åŒ…å«ä»¥ä¸‹æ•°å­—çš„ç»„åˆ", digits_options)
        include_digits = st.multiselect("âœ… ä»…ä¿ç•™åŒ…å«ä»¥ä¸‹æ•°å­—çš„ç»„åˆ", digits_options)
        search_keywords = st.text_input(
            "ğŸ” æœç´¢åŒ…å«æ•°å­—ï¼ˆå¤šä¸ªæ•°å­—å¯ç”¨é€—å·åˆ†éš”ï¼‰",
            help="æ¨¡ç³ŠåŒ¹é…ç»„åˆä¸­åŒ…å«çš„æ•°å­—ï¼Œä¸é™åˆ¶é¡ºåº",
        )

        def should_keep(combo: str) -> bool:
            parts = set(combo.split(","))
            if exclude_digits and any(d in parts for d in exclude_digits):
                return False
            if include_digits and not all(d in parts for d in include_digits):
                return False
            if search_keywords:
                keywords = re.findall(r"\d", search_keywords)
                if not all(k in parts for k in keywords):
                    return False
            return True

        filtered_combo_df = combo_df[combo_df["å·ç ç»„åˆ"].apply(should_keep)]
        st.markdown(f"#### ğŸ“‹ å·ç ç»„åˆç»Ÿè®¡ï¼ˆå…± {len(filtered_combo_df)} ä¸ªï¼‰")
        st.dataframe(filtered_combo_df.reset_index(drop=True), use_container_width=True)

# Top20 æŸ±çŠ¶å›¾
st.markdown("---")
chart_df = result_df[["AIæ˜µç§°", "å‘½ä¸­æœŸæ•°"]].head(20)
if not chart_df.empty:
    chart = (
        alt.Chart(chart_df)
        .mark_bar()
        .encode(
            x=alt.X("AIæ˜µç§°", sort="-y"),
            y=alt.Y("å‘½ä¸­æœŸæ•°"),
            tooltip=["AIæ˜µç§°", "å‘½ä¸­æœŸæ•°"],
        )
        .properties(width="container", height=360, title="ğŸ¯ å‘½ä¸­æœŸæ•° Top 20")
    )
    st.altair_chart(chart, use_container_width=True)
